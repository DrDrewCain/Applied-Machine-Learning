{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 \n",
    "Give 3 examples of continuous and categorical features in the dataset; choose one feature of each\n",
    "type and plot the histogram to illustrate the distribution.\n",
    "\n",
    "# Continuous Features:\n",
    "\n",
    "* MasVnrArea: Masonry veneer area in square feet\n",
    "* 1stFlrSF: First Floor square feet\n",
    "* GarageArea: Size of garage in square feet\n",
    "\n",
    "# Categorical Features:\n",
    "\n",
    "* MasVnrType: Masonry veneer type\n",
    "* ExterQual: Quality of the material on the exterior\n",
    "* BsmtCond: General condition of the basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "print(\"Full train dataset shape is {}\".format(df.shape))\n",
    "df.head(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Continuous features\n",
    "continuous_features = ['LotFrontage', 'LotArea', 'MasVnrArea']\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['MSSubClass', 'MSZoning', 'Street']\n",
    "\n",
    "# Initialize a 4x4 grid for subplots\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
    "\n",
    "# Flatten the axes array to easily iterate\n",
    "flattened_axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for continuous features\n",
    "for i, feature in enumerate(continuous_features):\n",
    "    ax = flattened_axes[i]\n",
    "    ax.hist(df[feature].dropna(), bins=30, edgecolor='black')\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Plot histograms for categorical features\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    ax = flattened_axes[i + len(continuous_features)]\n",
    "    df[feature].value_counts().plot(kind='bar', edgecolor='black', ax=ax)\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Remove unused subplots\n",
    "for i in range(len(continuous_features) + len(categorical_features), len(flattened_axes)):\n",
    "    fig.delaxes(flattened_axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous features\n",
    "continuous_features = ['LotFrontage', 'LotArea', 'MasVnrArea']\n",
    "\n",
    "# Categorical features\n",
    "categorical_features = ['MSSubClass', 'MSZoning', 'Street']\n",
    "\n",
    "# Handling Missing Values\n",
    "for feature in continuous_features:\n",
    "    df[feature].fillna(df[feature].median(), inplace=True)\n",
    "for feature in categorical_features:\n",
    "    df[feature].fillna(df[feature].mode()[0], inplace=True)\n",
    "\n",
    "# Normalizing Numerical Features\n",
    "scaler = MinMaxScaler()\n",
    "df[continuous_features] = scaler.fit_transform(df[continuous_features])\n",
    "\n",
    "# Encoding Categorical Features\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Update categorical_features list after one-hot encoding\n",
    "updated_categorical_features = [col for col in df.columns if any(feature in col for feature in categorical_features)]\n",
    "\n",
    "# Calculate grid size\n",
    "total_features = len(continuous_features) + len(updated_categorical_features)\n",
    "grid_size = int(np.ceil(np.sqrt(total_features)))\n",
    "\n",
    "# Initialize grid for subplots\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(16, 16))\n",
    "flattened_axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for continuous features\n",
    "for i, feature in enumerate(continuous_features):\n",
    "    ax = flattened_axes[i]\n",
    "    ax.hist(df[feature], bins=30, edgecolor='black')\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "\n",
    "# Plot histograms for categorical features\n",
    "for i, feature in enumerate(updated_categorical_features):\n",
    "    ax = flattened_axes[i + len(continuous_features)]\n",
    "    df[feature].value_counts().plot(kind='bar', edgecolor='black', ax=ax)\n",
    "    ax.set_title(f'Distribution of {feature}')\n",
    "\n",
    "# Remove unused subplots\n",
    "for i in range(total_features, len(flattened_axes)):\n",
    "    fig.delaxes(flattened_axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Pre-Process the data\n",
    "I combined Test + Training and pre-processed the combined dataset based on the given columns within the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Pre-Processing\n",
    "\n",
    "# Histogram for a numerical column\n",
    "sns.histplot(combined_df['LotArea'], kde=False)\n",
    "plt.title('Distribution of LotArea Before Preprocessing')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for a categorical column against a numerical column\n",
    "sns.boxplot(x='MSZoning', y='SalePrice', data=combined_df)\n",
    "plt.title('SalePrice by MSZoning Before Preprocessing')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging step:\n",
    "\n",
    "\n",
    "if combined_df.empty:\n",
    "    print(\"The DataFrame is empty. Check your data.\")\n",
    "print(\"Rows with any NA values: \", combined_df.isna().any(axis=1).sum())\n",
    "\n",
    "# Check the initial datasets\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "print(\"Train DataFrame shape:\", train_df.shape)\n",
    "print(\"Test DataFrame shape:\", test_df.shape)\n",
    "\n",
    "# Combine train and test datasets\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "print(\"Combined DataFrame shape:\", combined_df.shape)\n",
    "\n",
    "missing_cols = [col for col in numerical_cols if col not in combined_df.columns]\n",
    "if missing_cols:\n",
    "    print(f\"Missing columns: {missing_cols}\")\n",
    "else:\n",
    "    print(\"All numerical columns are present.\")\n",
    "\n",
    "na_counts = combined_df[numerical_cols].isna().sum()\n",
    "print(\"NA counts in numerical columns:\", na_counts)\n",
    "\n",
    "temp_df = combined_df[numerical_cols]\n",
    "print(\"Subset DataFrame shape:\", temp_df.shape)\n",
    "\n",
    "for col in numerical_cols:\n",
    "    median_val = combined_df[col].median()\n",
    "    combined_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "combined_df[numerical_cols] = scaler.fit_transform(combined_df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing CSV file\n",
    "training_df = pd.read_csv('./data/train.csv')\n",
    "testing_df = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Identify numerical columns (excluding 'SalePrice' for the testing set)\n",
    "numerical_cols = ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
    "                  'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', \n",
    "                  'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', \n",
    "                  'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', \n",
    "                  'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', \n",
    "                  'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', \n",
    "                  '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
    "\n",
    "# Step 1: Handle Missing Values for both training and testing\n",
    "for col in numerical_cols:\n",
    "    median_val = training_df[col].median()\n",
    "    training_df[col].fillna(median_val, inplace=True)\n",
    "    testing_df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "# Step 2: Normalize Numerical Variables for Training\n",
    "scaler_train = StandardScaler()\n",
    "training_df[numerical_cols + ['SalePrice']] = scaler_train.fit_transform(training_df[numerical_cols + ['SalePrice']])\n",
    "\n",
    "# Step 2: Normalize Numerical Variables for Testing\n",
    "scaler_test = StandardScaler()\n",
    "testing_df[numerical_cols] = scaler_test.fit_transform(testing_df[numerical_cols])\n",
    "\n",
    "# Step 3: Encode Categorical Variables for both training and testing\n",
    "categorical_cols = training_df.columns.difference(['Id'] + numerical_cols + ['SalePrice'])\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    combined_data = pd.concat([training_df[col], testing_df[col]]).astype(str)\n",
    "    label_encoder.fit(combined_data)\n",
    "    \n",
    "    training_df[col] = label_encoder.transform(training_df[col].astype(str))\n",
    "    testing_df[col] = label_encoder.transform(testing_df[col].astype(str))\n",
    "\n",
    "# Save the pre-processed data back to new CSV files\n",
    "training_df.to_csv('./data/pre-processed_training.csv', index=False)\n",
    "testing_df.to_csv('./data/pre-processed_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the original CSV into a DataFrame\n",
    "df = pd.read_csv('./data/pre-processed_training.csv')\n",
    "\n",
    "# Check if 'Street' is in the DataFrame columns\n",
    "if 'Street' in df.columns:\n",
    "    # One-hot encode 'Street'\n",
    "    df_onehot = pd.get_dummies(df, columns=['Street'], drop_first=True)\n",
    "    \n",
    "    # Update list and proceed as before\n",
    "    updated_categorical_features = [col for col in df_onehot.columns if 'Street' in col]\n",
    "    \n",
    "    # Initialize 2x2 grid for subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Plot histogram for original 'Street' feature\n",
    "    df['Street'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Original Street Feature')\n",
    "    \n",
    "    # Plot histogram for one-hot encoded 'Street' feature\n",
    "    df_onehot[updated_categorical_features].sum().plot(kind='bar', ax=axes[1])\n",
    "    axes[1].set_title('One-Hot Encoded Street Feature')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"'Street' column not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading your data\n",
    "df = pd.read_csv('./data/pre-processed_training.csv')\n",
    "\n",
    "# Features and target variable\n",
    "selected_features = ['OverallQual', 'YearBuilt', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars']\n",
    "X_train = df[selected_features]\n",
    "y_train = df['SalePrice']\n",
    "\n",
    "# OLS Model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = regressor.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Any NaN in y_train:\", torch.isnan(y_train_tensor).any())\n",
    "print(\"Any NaN in y_pred:\", np.isnan(y_pred).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Define model\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(len(selected_features), 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# Loss and optimizer with different learning rate\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n",
    "\n",
    "# To store loss values for plotting or analysis\n",
    "loss_values = []\n",
    "\n",
    "# Training with logging\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_tensor)\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Store loss\n",
    "    loss_values.append(loss.item())\n",
    "    \n",
    "    # Print loss every 1000 epochs\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_train_tensor).detach().numpy()\n",
    "\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed data\n",
    "training_df = pd.read_csv('./data/pre-processed_training.csv')\n",
    "testing_df = pd.read_csv('./data/pre-processed_testing.csv')\n",
    "\n",
    "# Initialize StandardScaler for features and target\n",
    "scaler_features = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "# Separate features and labels for training data\n",
    "X_train = training_df.drop(columns=['SalePrice'])\n",
    "y_train = training_df['SalePrice']\n",
    "X_test = testing_df  # Testing set doesn't have 'SalePrice'\n",
    "\n",
    "# Scale features\n",
    "X_train = scaler_features.fit_transform(X_train)\n",
    "X_test = scaler_features.transform(X_test)\n",
    "\n",
    "# Scale target ('SalePrice')\n",
    "y_train = scaler_target.fit_transform(y_train.to_frame()).ravel()\n",
    "\n",
    "# Feature selection\n",
    "selector = SelectKBest(score_func=f_regression, k=20)  # Select top 20 features\n",
    "X_train_new = selector.fit_transform(X_train, y_train)\n",
    "X_test_new = selector.transform(X_test)\n",
    "\n",
    "# Train the Ridge regression model\n",
    "model = Ridge(alpha=1.0)  # You can tune alpha for better performance\n",
    "model.fit(X_train_new, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_new)\n",
    "\n",
    "# Create a DataFrame to hold the predicted values\n",
    "predicted_df = pd.DataFrame(y_pred, columns=['Predicted_SalePrice'])\n",
    "\n",
    "# Re-scale the predicted and actual values back to the original scale\n",
    "predicted_df['Predicted_SalePrice'] = scaler_target.inverse_transform(predicted_df[['Predicted_SalePrice']])\n",
    "y_train_original_scale = scaler_target.inverse_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train_original_scale, bins=50, alpha=0.5, color='g', label='Actual SalePrice (Train)')\n",
    "plt.title('Actual Sale Prices in Training Data')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicted_df['Predicted_SalePrice'], bins=50, alpha=0.5, color='b', label='Predicted SalePrice')\n",
    "plt.title('Predicted Sale Prices in Test Data')\n",
    "plt.xlabel('SalePrice')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first CSV file into a DataFrame\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# Load the second CSV file into another DataFrame\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Combine the two DataFrames\n",
    "combined_df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame back to a new CSV file\n",
    "combined_df.to_csv('./data/combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
